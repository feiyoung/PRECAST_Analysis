{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b3d80b0a-f061-4a4e-bc6a-6911a8b58878",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Read HCC splicing/unsplicing matrices\n",
    "\n",
    "tutorial source: # https://dynamo-release.readthedocs.io/en/latest/notebooks/tutorial_pancreatic_endocrinogenesis.html\n",
    "\n",
    "combine all HCC sample, then do the RNA velocity analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e0f67cc-b06d-4950-8d68-4dada4966772",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Variable names are not unique. To make them unique, call `.var_names_make_unique`.\n",
      "Variable names are not unique. To make them unique, call `.var_names_make_unique`.\n",
      "Variable names are not unique. To make them unique, call `.var_names_make_unique`.\n",
      "Variable names are not unique. To make them unique, call `.var_names_make_unique`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TCGCGTAGCAGTGTCC-1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import scanpy as sc\n",
    "import scvelo as scv\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "#Read HCC splicing/unsplicing matrices\n",
    "\n",
    "## HCC1\n",
    "ldata1 = scv.read('scvelo_data/possorted_genome_bam_38RB4.loom', cache=False)\n",
    "# rename barcodes in order to merge:\n",
    "barcodes = [bc.split(':')[1] for bc in ldata1.obs.index.tolist()]\n",
    "ldata1.obs.index = barcodes\n",
    "ldata1.layers['spliced']\n",
    "\n",
    "## HCC2\n",
    "ldata2 = scv.read('scvelo_data/possorted_genome_bam_GIMO8.loom', cache=False)\n",
    "# rename barcodes in order to merge:\n",
    "barcodes = [bc.split(':')[1] for bc in ldata2.obs.index.tolist()]\n",
    "ldata2.obs.index = barcodes\n",
    "ldata2.layers['spliced']\n",
    "\n",
    "## HCC3\n",
    "ldata3 = scv.read('scvelo_data/possorted_genome_bam_OUUQ4.loom', cache=False)\n",
    "# rename barcodes in order to merge:\n",
    "barcodes = [bc.split(':')[1] for bc in ldata3.obs.index.tolist()]\n",
    "ldata3.obs.index = barcodes\n",
    "ldata3.layers['spliced']\n",
    "\n",
    "## HCC4\n",
    "ldata4 = scv.read('scvelo_data/possorted_genome_bam_YN3OB.loom', cache=False)\n",
    "# rename barcodes in order to merge:\n",
    "barcodes = [bc.split(':')[1] for bc in ldata4.obs.index.tolist()]\n",
    "ldata4.obs.index = barcodes\n",
    "ldata4.layers['spliced']\n",
    "\n",
    "ldata4\n",
    "\n",
    "#Combine all splicing data\n",
    "\n",
    "# make variable names unique\n",
    "ldata1.var_names_make_unique()\n",
    "ldata2.var_names_make_unique()\n",
    "ldata3.var_names_make_unique()\n",
    "ldata4.var_names_make_unique()\n",
    "# concatenate the three loom\n",
    "ldata = ldata1.concatenate([ldata2, ldata3, ldata4])\n",
    "ldata\n",
    "\n",
    "ldata.obs\n",
    "ldata.obs['batch'].index[0]\n",
    "\n",
    "## Load all count matrix data\n",
    "adata1 = sc.read_h5ad('scvelo_data/HCC4_anndata1.h5ad')\n",
    "adata2 = sc.read_h5ad('scvelo_data/HCC4_anndata2.h5ad')\n",
    "adata3 = sc.read_h5ad('scvelo_data/HCC4_anndata3.h5ad')\n",
    "adata4 = sc.read_h5ad('scvelo_data/HCC4_anndata4.h5ad')\n",
    "\n",
    "adata1.var_names_make_unique()\n",
    "adata2.var_names_make_unique()\n",
    "adata3.var_names_make_unique()\n",
    "adata4.var_names_make_unique()\n",
    "# concatenate the three loom\n",
    "adata_all = adata1.concatenate([adata2, adata3, adata4])\n",
    "\n",
    "adata_all\n",
    "\n",
    "# merge matrices into the original adata object\n",
    "adata = scv.utils.merge(adata_all, ldata)\n",
    "\n",
    "# # find the missing spot\n",
    "# missing_s = adata_all.obs['spot'][~adata_all.obs['spot'].isin(adata.obs['spot'])][0]\n",
    "# # dfObj.drop('b')\n",
    "# missing_s\n",
    "for i in range(adata.shape[0]):\n",
    "    if adata_all.obs['spot'][i]!=adata.obs['spot'][i]:\n",
    "        break\n",
    "missing_s = adata_all.obs['spot'][i]\n",
    "print(missing_s)\n",
    "missing_ind = np.where(adata4.obs['spot']==missing_s)\n",
    "adata4 = adata4.obs.drop(index=missing_s)\n",
    "\n",
    "## Read low-dimensional embeddings and clusters from iDR-SC \n",
    "import pyreadr\n",
    "os.chdir(\"/home/xuliao/LiuWei/HCC4Data\")\n",
    "hZ_data =  pyreadr.read_r('hZList_idrssc.rds')\n",
    "hZ = np.array(hZ_data['hZ_idrsc_HCC1'])\n",
    "for i in range(4-1):\n",
    "    hZ = np.concatenate((hZ, hZ_data['hZ_idrsc_HCC'+str(i+2)]))\n",
    "hZ_new = np.delete(hZ, (missing_ind), axis=0)\n",
    "cluster_data = pyreadr.read_r('hcc_cluster.rds')\n",
    "cluster = np.array(cluster_data['cluster_hcc1'])\n",
    "for i in range(4-1):\n",
    "    cluster = np.concatenate((cluster, cluster_data['cluster_hcc'+str(i+2)]))\n",
    "cluster_new = np.delete(cluster, (missing_ind), axis=0)\n",
    "cluster_dr = cluster_new.copy()\n",
    "cluster_dr[cluster_new == 3] = 1\n",
    "cluster_dr[cluster_new == 8] = 2\n",
    "cluster_dr[cluster_new == 9] = 3\n",
    "cluster_dr[cluster_new == 7] = 4\n",
    "cluster_dr[cluster_new == 1] = 5\n",
    "cluster_dr[cluster_new == 5] = 6\n",
    "cluster_dr[cluster_new == 6] = 7\n",
    "cluster_dr[cluster_new == 4] = 8\n",
    "cluster_dr[cluster_new == 2] = 9\n",
    "cluster_dr\n",
    "adata.obsm[\"Z\"] = hZ_new\n",
    "adata.obs[\"cluster\"] = cluster_dr\n",
    "adata.obs[\"clusters\"] = cluster_dr\n",
    "adata\n",
    "\n",
    "# adata.var['gene_id']\n",
    "sc.pp.normalize_total(adata, inplace=True)\n",
    "sc.pp.log1p(adata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f5c897fc-a8eb-42b4-872d-e08c4a1ed58c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered out 465 genes that are detected 20 counts (shared).\n",
      "WARNING: Did not normalize X as it looks processed already. To enforce normalization, set `enforce=True`.\n",
      "Normalized count data: spliced, unspliced.\n",
      "Skip filtering by dispersion since number of variables are less than `n_top_genes`.\n",
      "WARNING: Did not modify X as it looks preprocessed already.\n",
      "computing neighbors\n",
      "    finished (0:02:19) --> added \n",
      "    'distances' and 'connectivities', weighted adjacency matrices (adata.obsp)\n",
      "computing moments based on connectivities\n",
      "    finished (0:00:03) --> added \n",
      "    'Ms' and 'Mu', moments of un/spliced abundances (adata.layers)\n",
      "computing velocities\n",
      "    finished (0:00:03) --> added \n",
      "    'velocity', velocity vectors for each individual cell (adata.layers)\n",
      "recovering dynamics (using 1/40 cores)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "134fb1eb6c6b4c948c60555bfd517354",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/115 [00:00<?, ?gene/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    finished (0:10:50) --> added \n",
      "    'fit_pars', fitted parameters for splicing dynamics (adata.var)\n",
      "computing velocities\n",
      "    finished (0:00:09) --> added \n",
      "    'velocity', velocity vectors for each individual cell (adata.layers)\n",
      "computing velocity graph (using 1/40 cores)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e59456483bb47678de068dae218f5d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9812 [00:00<?, ?cells/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    finished (0:00:42) --> added \n",
      "    'velocity_graph', sparse matrix with cosine correlations (adata.uns)\n",
      "computing terminal states\n",
      "    identified 0 region of root cells and 4 regions of end points .\n",
      "    finished (0:00:11) --> added\n",
      "    'root_cells', root cells of Markov diffusion process (adata.obs)\n",
      "    'end_points', end points of Markov diffusion process (adata.obs)\n",
      "WARNING: No root cells detected. Consider specifying root cells to improve latent time prediction.\n",
      "computing latent time using root_cells as prior\n",
      "    finished (0:00:10) --> added \n",
      "    'latent_time', shared time (adata.obs)\n"
     ]
    }
   ],
   "source": [
    "scv.pp.filter_and_normalize(adata, min_shared_counts=20, n_top_genes=2000) \n",
    "scv.pp.moments(adata, n_neighbors=30, n_pcs=30)\n",
    "scv.tl.velocity(adata, mode='steady_state')\n",
    "\n",
    "scv.tl.recover_dynamics(adata)\n",
    "\n",
    "scv.tl.velocity(adata, mode='dynamical')\n",
    "\n",
    "scv.tl.velocity_graph(adata)\n",
    "\n",
    "scv.tl.recover_latent_time(adata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeaa24f3-77e0-459a-9cfe-867ba4235d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sc.pp.neighbors(adata, n_neighbors=50, n_pcs=100)\n",
    "sc.tl.tsne(adata)\n",
    "sc.tl.umap(adata)\n",
    "\n",
    "adata.obs['clusters'] = adata.obs['clusters'].astype(\"category\")\n",
    "adata.obs['clusters']  = adata.obs['clusters'].astype('string')\n",
    "# scv.pl.velocity_embedding(adata, basis='tsne') \n",
    "scv.pl.velocity_embedding_stream(adata, basis='pca',density=1, legend_fontsize=16, outline_color='white', arrow_color = 'k',arrow_style='-|>',linewidth=1.5, smooth=True, dpi=1000, save = 'scvelo_pca.png', min_mass=2, palette =[\"#CB181D\", \"#EF3B2C\", \"#FB6A4A\", \"#FC9272\", \"#FCBBA1\", \"#1f77b4\", \"#A65628\",  \"blue\", \"#00ee00\"]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bdb5aa7-17d5-4f2c-a04b-d0e8a954b719",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c33d19-f897-4eed-895a-8ea145114099",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
